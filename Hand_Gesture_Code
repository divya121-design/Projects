import numpy as np
import cv2

class HandGestureDetector:
    def __init__(self, region_top, region_bottom, region_left, region_right):
        self.background = None
        self.hand = None
        self.frames_elapsed = 0
        # Region of interest dimensions
        self.region_top = region_top
        self.region_bottom = region_bottom
        self.region_left = region_left
        self.region_right = region_right
        # Constants for calibration and object detection
        self.CALIBRATION_TIME = 30
        self.BG_WEIGHT = 0.5
        self.OBJ_THRESHOLD = 18

    def write_on_image(self, frame):
        # Display text on the frame based on the hand gesture detection
        text = "Searching..."
        if self.frames_elapsed < self.CALIBRATION_TIME:
            text = "Calibrating..."
        elif self.hand is None or not self.hand.isInFrame:
            text = "No hand detected"
        else:
            if self.hand.isWaving:
                text = "Waving"
            elif self.hand.fingers == 0:
                text = "Rock"
            elif self.hand.fingers == 1:
                text = "Pointing"
            elif self.hand.fingers == 2:
                text = "Scissors"

        cv2.putText(frame, text, (10, 20), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0, 0, 0), 2, cv2.LINE_AA)
        cv2.putText(frame, text, (10, 20), cv2.FONT_HERSHEY_COMPLEX, 0.4, (255, 255, 255), 1, cv2.LINE_AA)
        cv2.rectangle(frame, (self.region_left, self.region_top), (self.region_right, self.region_bottom), (255, 255, 255), 2)

    def get_region(self, frame):
        # Extract the region of interest from the frame
        region = frame[self.region_top:self.region_bottom, self.region_left:self.region_right]
        # Convert region to grayscale and apply Gaussian blur
        region = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)
        region = cv2.GaussianBlur(region, (5, 5), 0)
        return region

    def get_average(self, region):
        # Calculate the average background for background subtraction
        if self.background is None:
            self.background = region.copy().astype("float")
            return
        cv2.accumulateWeighted(region, self.background, self.BG_WEIGHT)

    def segment(self, region):
        # Segment the hand from the background using background subtraction
        diff = cv2.absdiff(self.background.astype(np.uint8), region)
        thresholded_region = cv2.threshold(diff, self.OBJ_THRESHOLD, 255, cv2.THRESH_BINARY)[1]
        (_, contours, _) = cv2.findContours(thresholded_region.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contours) == 0:
            if self.hand is not None:
                self.hand.isInFrame = False
            return
        else:
            if self.hand is not None:
                self.hand.isInFrame = True
            segmented_region = max(contours, key=cv2.contourArea)
            return (thresholded_region, segmented_region)

    def get_hand_data(self, thresholded_image, segmented_image):
        # Extract hand features and update hand object
        convexHull = cv2.convexHull(segmented_image)
        top = tuple(convexHull[convexHull[:, :, 1].argmin()][0])
        bottom = tuple(convexHull[convexHull[:, :, 1].argmax()][0])
        left = tuple(convexHull[convexHull[:, :, 0].argmin()][0])
        right = tuple(convexHull[convexHull[:, :, 0].argmax()][0])
        centerX = int((left[0] + right[0]) / 2)

        if self.hand is None:
            self.hand = HandData(top, bottom, left, right, centerX)
        else:
            self.hand.update(top, bottom, left, right)

        if self.frames_elapsed % 6 == 0:
            self.hand.check_for_waving(centerX)

        self.hand.gestureList.append(self.count_fingers(thresholded_image))
        if self.frames_elapsed % 12 == 0:
            self.hand.fingers = self.most_frequent(self.hand.gestureList)
            self.hand.gestureList.clear()

    def count_fingers(self, thresholded_image):
        # Count the number of fingers in the hand region
        line_height = int(self.hand.top[1] + (0.2 * (self.hand.bottom[1] - self.hand.top[1])))
        line = np.zeros(thresholded_image.shape[:2], dtype=int)
        cv2.line(line, (thresholded_image.shape[1], line_height), (0, line_height), 255, 1)
        line = cv2.bitwise_and(thresholded_image, thresholded_image, mask=line.astype(np.uint8))
        (_, contours, _) = cv2.findContours(line.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
        fingers = 0
        for curr in contours:
            width = len(curr)
            if width < 3 * abs(self.hand.right[0] - self.hand.left[0]) / 4 and width > 5:
                fingers += 1
        return fingers

    def most_frequent(self, input_list):
        # Find the most frequent element in a list
        freq_dict = {}
        max_freq = 0
        most_freq = None
        for item in reversed(input_list):
            freq_dict[item] = freq_dict.get(item, 0) + 1
            if freq_dict[item] >= max_freq:
                max_freq = freq_dict[item]
                most_freq = item
        return most_freq

class HandData:
    def __init__(self, top, bottom, left, right, centerX):
        # Store hand data
        self.top = top
        self.bottom = bottom
        self.left = left
        self.right = right
        self.centerX = centerX
        self.prevCenterX = 0
        self.isInFrame = False
        self.isWaving = False
        self.fingers = None
        self.gestureList = []

    def update(self, top, bottom, left, right):
        # Update hand data
        self.top = top
        self.bottom = bottom
        self.left = left
        self.right = right

    def check_for_waving(self, centerX):
        # Check for waving motion
        self.prevCenterX = self.centerX
        self.centerX = centerX
        if abs(self.centerX - self.prevCenterX > 3):
            self.isWaving = True
        else:
            self.isWaving = False

if __name__ == "__main__":
    # Region of interest dimensions
    region_top = 0
    region_bottom = int(2 * 200 / 3)
    region_left = int(300 / 2)
    region_right = 300
    # Initialize hand gesture detector
    detector = HandGestureDetector(region_top, region_bottom, region_left, region_right)

    # Open camera capture
    capture = cv2.VideoCapture(1)

    while (True):
        # Read frame from camera
        ret, frame = capture.read()
        if not ret:  # Check if frame was successfully captured
            print("Error: Failed to capture frame from the camera.")
            break

        # Get frame height and width
        frame_height, frame_width = frame.shape[:2]
        # Resize and flip frame
        frame = cv2.resize(frame, (frame_width, frame_height))
        frame = cv2.flip(frame, 1)
        
        # Extract region of interest
        region = detector.get_region(frame)
        if detector.frames_elapsed < detector.CALIBRATION_TIME:
            detector.get_average(region)
        else:
            region_pair = detector.segment(region)
            if region_pair is not None:
                (thresholded_region, segmented_region) = region_pair
                cv2.drawContours(region, [segmented_region], -1, (255, 255, 255))
                cv2.imshow("Segmented Image", region)
                detector.get_hand_data(thresholded_region, segmented_region)
        
        # Write hand gesture information on the frame
        detector.write_on_image(frame)
        cv2.imshow("Camera Input", frame)
        detector.frames_elapsed += 1
        
        # Check for exit key
        if (cv2.waitKey(1) & 0xFF == ord('x')):
            break

    # Release capture and destroy windows
    capture.release()
    cv2.destroyAllWindows()
